
in_channels: 240
activation: ReLU



model:
  type : Inception time
  kwargs:
    layers:
      - name: InceptionBlock
        kwargs:
          in_channels: 1
          bottleneck_channels: 16
          n_filters: 20
          kernel_sizes: [17, 65, 131]
          use_residual: True
        id: inceptionblock1

      - name: InceptionBlock
        kwargs:
          in_channels: 80 # n_filters x 4
          bottleneck_channels: 80
          n_filters: 20
          kernel_sizes: [17, 65, 131]
          use_residual: True
        id: inceptionblock2

      - name: AdaptiveAvgPool1d
        kwargs:
          output_size: 2
        id: adaptivepool
      - name: Flatten
        kwargs:
          start_dim: 1
      - name: Linear
        kwargs:
          in_features: 4800 # outputsize of adaptivep x n_filters x 4
          out_features: 1024
        id: linear1
      - name: relu
      - name: Linear
        kwargs:
          in_features: 1024
          out_features: 6
        id: linear2

training_params:
  epoch_num: 10
  lr: 0.001
  dataloader_params:
    batch_size: 256


eval_params:
  batch_size: 256


# TODO: RENAME USE GPT
tensorboard_log_frequency:
  validation_loss: 128
  accuracy: 128
  confusion_matrix: 128

bottleneck:
  - name: Conv1d
    kwargs:
      in_channels:
      out_channels:
      kernel_size: 1
      bias: False


