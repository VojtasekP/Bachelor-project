
lr: 0.01

model:
  class: LSTM
  attention: False
  kwargs:
    layers:
      - name: LSTM
        kwargs:
          input_size: 1000
          hidden_size: 512
          num_layers: 2
          batch_first: True
          bidirectional: True
      - name: Linear
        kwargs:
          in_features: 1024
          out_features: 9



training_params:
  epoch_num: 20
  dataloader_params:
    batch_size: 256
    shuffle: true

eval_params:
  batch_size: 256
  shuffle: true

