{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-04-21T08:26:06.275048Z",
     "start_time": "2024-04-21T08:26:04.936512Z"
    }
   },
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from abc import ABC\n",
    "import warnings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.pipeline import Pipeline\n",
    "from signal_dataset import SignalDataset\n",
    "from sklearn.metrics import classification_report\n",
    "import re\n",
    "from pathlib import Path\n",
    "from sklearn.base import BaseEstimator, ClassifierMixin\n",
    "from sklearn.utils.validation import check_X_y\n",
    "import yaml\n",
    "import re\n",
    "from pathlib import Path\n",
    "import abc\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "import yaml\n",
    "from typing import Callable\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, classification_report\n",
    "from torch.utils.data import DataLoader, Dataset, random_split\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from tqdm import trange\n",
    "import seaborn as sns\n",
    "import networks\n",
    "from signal_dataset import SignalDataset\n"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "source": [
    "sr = 1562500\n",
    "signal_data_dir = \"/home/petr/Documents/Motor_project/AE_PETR_motor/\"\n",
    "bin_setup = [{\"label\": i.stem, \"channels\": len(list(i.glob('*.bin'))), \"interval\": [0, 15 * sr], \"bin_path\": list(i.glob('*.bin'))[0]} for i in\n",
    "             Path(signal_data_dir).glob('WUP*') if re.search(r'\\d$', i.stem)]\n",
    "\n",
    "sd = SignalDataset(step=1000, window_size=1000, bin_setup=bin_setup, device=\"cpu\", source_dtype=\"float32\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-21T08:26:06.977681Z",
     "start_time": "2024-04-21T08:26:06.276073Z"
    }
   },
   "id": "612489b2d8ddfe1",
   "outputs": [],
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "source": "train_data, test_data = random_split(sd, [0.8, 0.2])",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-21T08:26:07.008027Z",
     "start_time": "2024-04-21T08:26:06.978316Z"
    }
   },
   "id": "8eb748244b3a5544",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-21T08:26:09.428743Z",
     "start_time": "2024-04-21T08:26:07.631094Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "DEVICE = \"cuda\"\n",
    "\n",
    "\n",
    "class SignalModel:\n",
    "    def __init__(self, config_path: Path):\n",
    "        self.config_path = config_path\n",
    "        self._load_config()\n",
    "        self._model = self.init_model()\n",
    "        self._transform = self.init_transform()\n",
    "        self._load_config()\n",
    "        \n",
    "    @abc.abstractmethod\n",
    "    def _load_config(self):\n",
    "        pass\n",
    "    \n",
    "    @abc.abstractmethod\n",
    "    def init_model(self):\n",
    "        pass\n",
    "\n",
    "    @abc.abstractmethod\n",
    "    def train(self, train_dataset: Dataset, test_dataset: Dataset) -> None:\n",
    "        pass\n",
    "\n",
    "    @abc.abstractmethod                   # raw outputs, targets\n",
    "    def _evaluate(self, dataset: Dataset) -> (np.ndarray, np.ndarray):\n",
    "        pass\n",
    "    \n",
    "    @abc.abstractmethod\n",
    "    def predict(self, x: np.ndarray) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Predicts the label of one or multiple signals.\n",
    "        \"\"\"\n",
    "        pass\n",
    "    \n",
    "    @abc.abstractmethod\n",
    "    def save(self, path: Path):\n",
    "        pass\n",
    "    \n",
    "    def init_transform(self) -> Callable:\n",
    "\n",
    "        def transform(x: np.ndarray) -> np.ndarray:\n",
    "            return x\n",
    "\n",
    "        return transform\n",
    "    \n",
    "    # def _evaluate(self, x: np.ndarray) -> np.ndarray:\n",
    "    #     x = self._transform(x)\n",
    "    #     return self.inference(x)\n",
    "\n",
    "    def plot_confusion_matrix(self, x_input: np.ndarray, y_true: np.ndarray):\n",
    "        y_pred = self._model.predict(x_input)\n",
    "        class_num = 9  # in future will not be hard coded\n",
    "        cm = confusion_matrix(y_true, y_pred, labels=np.arange(class_num))\n",
    "        plt.figure(figsize=(10, 10))\n",
    "        plt.imshow(cm, cmap='Greens')\n",
    "        for i in range(class_num):\n",
    "            for j in range(class_num):\n",
    "                plt.text(j, i, cm[i, j], ha=\"center\", va=\"bottom\", color='gray')\n",
    "                plt.text(j, i, str(j), ha=\"center\", va=\"top\", color='gray')\n",
    "\n",
    "    def accuracy(self, x_input: np.ndarray, y_true: np.ndarray) -> float:\n",
    "        y_pred = self._model.predict(x_input)\n",
    "        return accuracy_score(y_true, y_pred)\n",
    "    \n",
    "    def precision_and_recall(self, x_input: np.ndarray, y_true: np.ndarray) -> (float, float):\n",
    "        y_pred = self._model.predict(x_input)\n",
    "        cr = classification_report(y_true, y_pred, zero_division=0, output_dict=True)\n",
    "        return cr[\"macro avg\"][\"precision\"], cr[\"macro avg\"][\"recall\"]\n",
    "    \n",
    "    def classification_report(self, x_input: np.ndarray, y_true: np.ndarray) -> dict:\n",
    "        y_pred = self._model.predict(x_input)\n",
    "        return classification_report(y_true, y_pred, zero_division=0, output_dict=True)"
   ],
   "id": "523af06032ef9686",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-21T08:26:09.458067Z",
     "start_time": "2024-04-21T08:26:09.429892Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# x_test = np.asarray([data[0] for data in dataloader])\n",
    "# y_test = np.asarray([data[1] for data in dataloader])\n",
    "class SklearnModel(SignalModel, ABC):\n",
    "    def __init__(self, config_path: Path):\n",
    "        super().__init__(config_path)\n",
    "        self.config_path = config_path\n",
    "        self._model = self.init_model()\n",
    "    def _load_config(self):\n",
    "        with self.config_path.open(mode=\"r\") as yaml_file:\n",
    "            self.config = yaml.load(yaml_file, Loader=yaml.SafeLoader)\n",
    "            self.model_config = self.config[\"model\"]\n",
    "    def init_model(self):\n",
    "        match self.model_config[\"type\"]:\n",
    "            case \"DummyClassifier\":\n",
    "                return DummyClassifier()\n",
    "            case \"RandomForestClassifier\":\n",
    "                return RandomForestClassifier()\n",
    "    def train(self, train_dataset: Dataset, test_dataset: Dataset) -> None:\n",
    "        x_train = np.asarray([data[0] for data in train_dataset])\n",
    "        y_train = np.asarray([data[1] for data in train_dataset])\n",
    "        self._model.fit(x_train, y_train)    \n",
    "        \n",
    "    def predict(self, x: np.ndarray) -> np.ndarray:\n",
    "        return self._model.predict(x)\n",
    "    \n",
    "    def _evaluate(self, dataset: Dataset) -> np.ndarray:\n",
    "        x = np.asarray([data[0] for data in dataset])        \n",
    "        return self.predict(x)\n",
    "        "
   ],
   "id": "996245ffe884c948",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-21T08:26:09.492317Z",
     "start_time": "2024-04-21T08:26:09.458881Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class NeuroNet(SignalModel, ABC):\n",
    "\n",
    "    def __init__(self, config_path: Path, tensorboard: bool = False):\n",
    "        super().__init__(config_path)\n",
    "        self.config_path = config_path\n",
    "        self.tensorboard = tensorboard\n",
    "\n",
    "        self.criterion = nn.CrossEntropyLoss()\n",
    "        self.writer = SummaryWriter(\n",
    "            comment=f\"_{config_path.stem}_{self.config['eval_params']['batch_size']}\")\n",
    "        \n",
    "        self.train_loss = []\n",
    "        self.val_loss = []\n",
    "        self.val_accuracy = []\n",
    "        self.total_batch_id = 1\n",
    "        self.epoch_trained = 0\n",
    "        self.train_set: bool\n",
    "        self.pretrained = False \n",
    "        \n",
    "    def _load_config(self) -> None:\n",
    "        with self.config_path.open(mode=\"r\") as yaml_file:\n",
    "            self.config = yaml.load(yaml_file, Loader=yaml.SafeLoader)\n",
    "            self.model_config = self.config[\"model\"]\n",
    "\n",
    "        if isinstance(self.model_config[\"kwargs\"][\"layers\"], list):\n",
    "            self.layers_configs = []\n",
    "            for layer_config in self.model_config[\"kwargs\"][\"layers\"]:\n",
    "                self.layers_configs.append(layer_config)\n",
    "        else:\n",
    "            self.layers_configs = {}\n",
    "            for name, kwargs in self.model_config[\"kwargs\"][\"layers\"].items():\n",
    "                self.layers_configs[name] = kwargs\n",
    "\n",
    "    def init_model(self):\n",
    "        # TODO: make in_channels as parameter\n",
    "        match self.model_config[\"type\"]:\n",
    "            case \"MLP\":\n",
    "                return networks.MLP(self.layers_configs)\n",
    "            case \"Inception time\" | \"Inception\" | \"Inception_time\":\n",
    "                return networks.InceptionTime(self.layers_configs)\n",
    "            case \"LSTM\" | \"GRU\":\n",
    "                # return networks.RNN(self.layers_configs)\n",
    "                return networks.RNN(self.layers_configs, attention=self.model_config[\"attention\"])\n",
    "            case \"CNN\":\n",
    "                return networks.CNNOld()\n",
    "            case \"LSTM-FCN\" | \"lstm_fcn\":\n",
    "                return networks.RnnFcn(self.layers_configs)\n",
    "\n",
    "    def train(self, train_dataset: Dataset, test_dataset: Dataset) -> None:\n",
    "\n",
    "        self._load_config()\n",
    "        self._model.to(DEVICE)\n",
    "\n",
    "        optimizer = optim.AdamW(self._model.parameters(), self.config[\"lr\"])\n",
    "        scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer,\n",
    "                                                               T_max=self.config[\"training_params\"][\n",
    "                                                                   \"epoch_num\"])\n",
    "\n",
    "        train_dataloader = DataLoader(train_dataset,\n",
    "                                      **self.config[\"training_params\"].get(\"dataloader_params\", {}))\n",
    "        test_dataloader = DataLoader(test_dataset, **self.config[\"eval_params\"])\n",
    "\n",
    "        epochs = trange(self.config[\"training_params\"][\"epoch_num\"], ncols=100)  # , desc='Epoch #', leave=True)\n",
    "\n",
    "        for epoch in epochs:\n",
    "            for (inputs, targets) in train_dataloader:\n",
    "                self._model.train()\n",
    "                inputs, targets = inputs.to(DEVICE), targets.to(DEVICE)\n",
    "                optimizer.zero_grad()\n",
    "                outputs = self._model(inputs)\n",
    "                loss = self.criterion(outputs, targets)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                self.train_loss.append(loss)\n",
    "                self.writer.add_scalar(tag='Loss/train', scalar_value=loss, global_step=self.total_batch_id)\n",
    "                \n",
    "                if self.tensorboard:\n",
    "                    self.train_set = False\n",
    "                    self.calculate_metrics(test_dataset)\n",
    "                    self.train_set = True\n",
    "                    self.calculate_metrics(train_dataset)\n",
    "\n",
    "                epochs.set_description(f\"Epoch #{self.epoch_trained + 1}\")\n",
    "                self.total_batch_id += 1\n",
    "                \n",
    "            last_lr = scheduler.get_last_lr()[0]\n",
    "            self.writer.add_scalar(tag='learning rate', scalar_value=last_lr, global_step=self.epoch_trained)\n",
    "            self.epoch_trained += 1\n",
    "            scheduler.step()\n",
    "\n",
    "            # epochs.refresh()\n",
    "            #\n",
    "            # self.eval_model(testing_data, writer, )\n",
    "\n",
    "            self.pretrained = True\n",
    "            if self.tensorboard:\n",
    "                warnings.warn(\"Tensorboard summary writer is not closed\")\n",
    "            \n",
    "    def predict(self, x: np.ndarray) -> np.ndarray:\n",
    "        x = torch.from_numpy(x).to(DEVICE)\n",
    "        if x.ndim == 1:\n",
    "            x = torch.reshape(x, (1, -1))\n",
    "        # self._model.to(\"cpu\")\n",
    "        output = self._model(x)\n",
    "        prediction = torch.argmax(output, dim=1)\n",
    "        return prediction.cpu().numpy()\n",
    "\n",
    "    def _evaluate(self, dataset: Dataset) -> (np.ndarray, np.ndarray):\n",
    "        self._model.eval()\n",
    "        outputs = []\n",
    "        targets = []\n",
    "        if self.train_set:\n",
    "            dataloader = DataLoader(dataset, **self.config[\"training_params\"].get(\"dataloader_params\", {}))\n",
    "        else:\n",
    "            dataloader = DataLoader(dataset, **self.config[\"eval_params\"])\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for i, (input, target) in enumerate(dataloader):\n",
    "                input, target = input.to(DEVICE), target.to(DEVICE)\n",
    "                output = self._model(input)\n",
    "                outputs.extend(output.cpu().numpy())  # appends list of predictions for one batch to predictions over selected set\n",
    "                targets.extend(target.cpu().numpy())\n",
    "        # shapes: (num_of_examples, 9), (num_of_examples,)\n",
    "        return np.asarray(outputs), np.asarray(targets)\n",
    "\n",
    "    def calculate_metrics(self, dataset: Dataset) -> None:\n",
    "        if (self.total_batch_id % self.config[\"metrics\"][\"confusion_matrix\"] == 0 or \n",
    "            self.total_batch_id % self.config[\"metrics\"][\"classification_report\"] == 0 or\n",
    "            self.total_batch_id % self.config[\"metrics\"][\"validation_loss\"] == 0):\n",
    "            \n",
    "            class_num = 9\n",
    "            tag = \"train\" if self.train_set else \"val\"\n",
    "            outputs, targets = self._evaluate(dataset)\n",
    "            predictions = np.argmax(outputs, axis=1)  # makes the correct predictions\n",
    "            \n",
    "            if not self.train_set and self.total_batch_id % self.config[\"tensorboard_params\"][\"validation_loss\"] == 0:\n",
    "                val_loss = self.criterion(torch.tensor(outputs),torch.tensor(targets))\n",
    "                self.writer.add_scalar(tag=f'Loss/{tag}', scalar_value=val_loss, global_step=self.total_batch_id)\n",
    "\n",
    "            if self.total_batch_id % self.config[\"metrics\"][\"classification_report\"] == 0:\n",
    "                cr = classification_report(targets, predictions, labels=np.arange(class_num), output_dict=True, zero_division=0)\n",
    "                \n",
    "                self.writer.add_scalar(tag=f'Accuracy/{tag}', \n",
    "                                       scalar_value=cr[\"accuracy\"], global_step=self.total_batch_id)\n",
    "                self.writer.add_scalar(tag=f'Precision/{tag}', \n",
    "                                       scalar_value=cr[\"macro avg\"][\"precision\"], global_step=self.total_batch_id)\n",
    "                self.writer.add_scalar(tag=f'Recall/{tag}', \n",
    "                                       scalar_value=cr[\"macro avg\"]['recall'], global_step=self.total_batch_id)\n",
    "                self.writer.add_scalar(tag=f'F1-score/{tag}', \n",
    "                                       scalar_value=cr[\"macro avg\"][\"f1-score\"], global_step=self.total_batch_id)\n",
    "                \n",
    "    \n",
    "            if self.total_batch_id % self.config[\"tensorboard_params\"][\"confusion_matrix\"] == 0:\n",
    "                plt.figure(figsize=(12, 7))\n",
    "                cm = confusion_matrix(targets, predictions, labels=np.arange(class_num))\n",
    "                df_cm = pd.DataFrame(cm / np.sum(cm, axis=1)[:, None], index=[i for i in range(class_num)],\n",
    "                                     columns=[i for i in range(class_num)])\n",
    "                self.writer.add_figure(tag=f\"Confusion matrix/{tag}\",\n",
    "                                       figure=sns.heatmap(df_cm, annot=True, fmt=\".1f\").get_figure(),\n",
    "                                       global_step=self.total_batch_id)\n",
    "            \n",
    "    def save(self, path: str) -> None:\n",
    "        torch.save(self._model, Path(path))\n",
    "\n",
    "    def close_writer(self):\n",
    "        if self.tensorboard:\n",
    "            self.writer.close()\n",
    "            print(\"Tensorboard summary writer is closed\")\n",
    "        else: print(\"No Tensorboard summary writer found\")"
   ],
   "id": "ced38c2cfb5a9fa",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-21T07:13:56.162790Z",
     "start_time": "2024-04-21T07:13:56.020260Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "# dummy_classifier = SklearnModel(Path(\"non_dl_yaml_configs/dummy_classifier.yaml\"))\n",
    "neuro_net = NeuroNet(Path(\"nn_yaml_configs/LSTM-FCN.yaml\"))\n"
   ],
   "id": "b401eec108a4a504",
   "outputs": [],
   "execution_count": 15
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-21T07:14:09.072318Z",
     "start_time": "2024-04-21T07:13:57.042501Z"
    }
   },
   "cell_type": "code",
   "source": "neuro_net.train(train_data, test_data)",
   "id": "fa2ed9a754ebabfe",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #1: 100%|███████████████████████████████████████████████████████| 1/1 [00:11<00:00, 11.98s/it]\n"
     ]
    }
   ],
   "execution_count": 16
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-21T06:59:07.343583Z",
     "start_time": "2024-04-21T06:59:07.311187Z"
    }
   },
   "cell_type": "code",
   "source": "neuro_net.close_writer()",
   "id": "498acd5a097c9469",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No Tensorboard summary writer found\n"
     ]
    }
   ],
   "execution_count": 32
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-21T07:14:10.680406Z",
     "start_time": "2024-04-21T07:14:10.647716Z"
    }
   },
   "cell_type": "code",
   "source": "dummy_classifier = SklearnModel(Path(\"non_dl_yaml_configs/dummy_classifier.yaml\"))",
   "id": "723d08374372159f",
   "outputs": [],
   "execution_count": 17
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-21T08:26:11.949721Z",
     "start_time": "2024-04-21T08:26:11.837825Z"
    }
   },
   "cell_type": "code",
   "source": [
    "x_test = np.asarray([data[0] for data in test_data]) \n",
    "y_test = np.asarray([data[1] for data in test_data]) "
   ],
   "id": "7f0790a3600fb692",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-21T08:26:17.737880Z",
     "start_time": "2024-04-21T08:26:17.705015Z"
    }
   },
   "cell_type": "code",
   "source": "x_test.shape",
   "id": "a15d045635b04c00",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(42186, 1000)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-21T07:14:12.149453Z",
     "start_time": "2024-04-21T07:14:11.765125Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "dummy_classifier.train(train_data, test_data)\n",
    "\n"
   ],
   "id": "a5834a8408dafec",
   "outputs": [],
   "execution_count": 19
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-21T07:14:13.391051Z",
     "start_time": "2024-04-21T07:14:13.366820Z"
    }
   },
   "cell_type": "code",
   "source": "models = [dummy_classifier, neuro_net]",
   "id": "ef92d6c93d70c45d",
   "outputs": [],
   "execution_count": 20
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-21T07:14:14.768109Z",
     "start_time": "2024-04-21T07:14:13.900132Z"
    }
   },
   "cell_type": "code",
   "source": [
    "for model in models:\n",
    "    y_pred = model.predict(x_test)\n",
    "    print(f\"{model}: {model.accuracy(y_test, y_pred)}\")"
   ],
   "id": "69f3b927e35a70dd",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<__main__.SklearnModel object at 0x7c9c57fa9650>: 1.0\n"
     ]
    },
    {
     "ename": "OutOfMemoryError",
     "evalue": "CUDA out of memory. Tried to allocate 1.01 GiB. GPU 0 has a total capacty of 7.79 GiB of which 409.62 MiB is free. Including non-PyTorch memory, this process has 7.37 GiB memory in use. Of the allocated memory 6.47 GiB is allocated by PyTorch, and 706.01 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mOutOfMemoryError\u001B[0m                          Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[21], line 2\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m model \u001B[38;5;129;01min\u001B[39;00m models:\n\u001B[0;32m----> 2\u001B[0m     y_pred \u001B[38;5;241m=\u001B[39m model\u001B[38;5;241m.\u001B[39mpredict(x_test)\n\u001B[1;32m      3\u001B[0m     \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mmodel\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mmodel\u001B[38;5;241m.\u001B[39maccuracy(y_test,\u001B[38;5;250m \u001B[39my_pred)\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m)\n",
      "Cell \u001B[0;32mIn[14], line 104\u001B[0m, in \u001B[0;36mNeuroNet.predict\u001B[0;34m(self, x)\u001B[0m\n\u001B[1;32m    102\u001B[0m     x \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mreshape(x, (\u001B[38;5;241m1\u001B[39m, \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m))\n\u001B[1;32m    103\u001B[0m \u001B[38;5;66;03m# self._model.to(\"cpu\")\u001B[39;00m\n\u001B[0;32m--> 104\u001B[0m output \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_model(x)\n\u001B[1;32m    105\u001B[0m prediction \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39margmax(output, dim\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1\u001B[39m)\n\u001B[1;32m    106\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m prediction\u001B[38;5;241m.\u001B[39mcpu()\u001B[38;5;241m.\u001B[39mnumpy()\n",
      "File \u001B[0;32m~/anaconda3/envs/t2/lib/python3.11/site-packages/torch/nn/modules/module.py:1518\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1516\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[1;32m   1517\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m-> 1518\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[0;32m~/anaconda3/envs/t2/lib/python3.11/site-packages/torch/nn/modules/module.py:1527\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1522\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1523\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1524\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[1;32m   1525\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1526\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1527\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m forward_call(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[1;32m   1529\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m   1530\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "File \u001B[0;32m~/Documents/bachelor_project/Project/networks.py:189\u001B[0m, in \u001B[0;36mRnnFcn.forward\u001B[0;34m(self, x)\u001B[0m\n\u001B[1;32m    187\u001B[0m lstm_output, _ \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mlstm(\u001B[38;5;28minput\u001B[39m\u001B[38;5;241m=\u001B[39mx)\n\u001B[1;32m    188\u001B[0m lstm_output \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdropout(lstm_output)\n\u001B[0;32m--> 189\u001B[0m fcn_output \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mfcn(x)\n\u001B[1;32m    190\u001B[0m concat_output \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mcat((fcn_output, lstm_output), \u001B[38;5;241m1\u001B[39m)\n\u001B[1;32m    191\u001B[0m concat_output \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mflatten(concat_output, \u001B[38;5;241m1\u001B[39m)\n",
      "File \u001B[0;32m~/anaconda3/envs/t2/lib/python3.11/site-packages/torch/nn/modules/module.py:1518\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1516\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[1;32m   1517\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m-> 1518\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[0;32m~/anaconda3/envs/t2/lib/python3.11/site-packages/torch/nn/modules/module.py:1527\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1522\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1523\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1524\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[1;32m   1525\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1526\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1527\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m forward_call(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[1;32m   1529\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m   1530\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "File \u001B[0;32m~/anaconda3/envs/t2/lib/python3.11/site-packages/torch/nn/modules/container.py:215\u001B[0m, in \u001B[0;36mSequential.forward\u001B[0;34m(self, input)\u001B[0m\n\u001B[1;32m    213\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mforward\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;28minput\u001B[39m):\n\u001B[1;32m    214\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m module \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m:\n\u001B[0;32m--> 215\u001B[0m         \u001B[38;5;28minput\u001B[39m \u001B[38;5;241m=\u001B[39m module(\u001B[38;5;28minput\u001B[39m)\n\u001B[1;32m    216\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28minput\u001B[39m\n",
      "File \u001B[0;32m~/anaconda3/envs/t2/lib/python3.11/site-packages/torch/nn/modules/module.py:1518\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1516\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[1;32m   1517\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m-> 1518\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[0;32m~/anaconda3/envs/t2/lib/python3.11/site-packages/torch/nn/modules/module.py:1527\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1522\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1523\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1524\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[1;32m   1525\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1526\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1527\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m forward_call(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[1;32m   1529\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m   1530\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "File \u001B[0;32m~/anaconda3/envs/t2/lib/python3.11/site-packages/torch/nn/modules/batchnorm.py:171\u001B[0m, in \u001B[0;36m_BatchNorm.forward\u001B[0;34m(self, input)\u001B[0m\n\u001B[1;32m    164\u001B[0m     bn_training \u001B[38;5;241m=\u001B[39m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mrunning_mean \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m) \u001B[38;5;129;01mand\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mrunning_var \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m)\n\u001B[1;32m    166\u001B[0m \u001B[38;5;250m\u001B[39m\u001B[38;5;124mr\u001B[39m\u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m    167\u001B[0m \u001B[38;5;124;03mBuffers are only updated if they are to be tracked and we are in training mode. Thus they only need to be\u001B[39;00m\n\u001B[1;32m    168\u001B[0m \u001B[38;5;124;03mpassed when the update should occur (i.e. in training mode when they are tracked), or when buffer stats are\u001B[39;00m\n\u001B[1;32m    169\u001B[0m \u001B[38;5;124;03mused for normalization (i.e. in eval mode when buffers are not None).\u001B[39;00m\n\u001B[1;32m    170\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m--> 171\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m F\u001B[38;5;241m.\u001B[39mbatch_norm(\n\u001B[1;32m    172\u001B[0m     \u001B[38;5;28minput\u001B[39m,\n\u001B[1;32m    173\u001B[0m     \u001B[38;5;66;03m# If buffers are not to be tracked, ensure that they won't be updated\u001B[39;00m\n\u001B[1;32m    174\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mrunning_mean\n\u001B[1;32m    175\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtraining \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtrack_running_stats\n\u001B[1;32m    176\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m,\n\u001B[1;32m    177\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mrunning_var \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtraining \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtrack_running_stats \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m,\n\u001B[1;32m    178\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mweight,\n\u001B[1;32m    179\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mbias,\n\u001B[1;32m    180\u001B[0m     bn_training,\n\u001B[1;32m    181\u001B[0m     exponential_average_factor,\n\u001B[1;32m    182\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39meps,\n\u001B[1;32m    183\u001B[0m )\n",
      "File \u001B[0;32m~/anaconda3/envs/t2/lib/python3.11/site-packages/torch/nn/functional.py:2478\u001B[0m, in \u001B[0;36mbatch_norm\u001B[0;34m(input, running_mean, running_var, weight, bias, training, momentum, eps)\u001B[0m\n\u001B[1;32m   2475\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m training:\n\u001B[1;32m   2476\u001B[0m     _verify_batch_size(\u001B[38;5;28minput\u001B[39m\u001B[38;5;241m.\u001B[39msize())\n\u001B[0;32m-> 2478\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m torch\u001B[38;5;241m.\u001B[39mbatch_norm(\n\u001B[1;32m   2479\u001B[0m     \u001B[38;5;28minput\u001B[39m, weight, bias, running_mean, running_var, training, momentum, eps, torch\u001B[38;5;241m.\u001B[39mbackends\u001B[38;5;241m.\u001B[39mcudnn\u001B[38;5;241m.\u001B[39menabled\n\u001B[1;32m   2480\u001B[0m )\n",
      "\u001B[0;31mOutOfMemoryError\u001B[0m: CUDA out of memory. Tried to allocate 1.01 GiB. GPU 0 has a total capacty of 7.79 GiB of which 409.62 MiB is free. Including non-PyTorch memory, this process has 7.37 GiB memory in use. Of the allocated memory 6.47 GiB is allocated by PyTorch, and 706.01 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF"
     ]
    }
   ],
   "execution_count": 21
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-21T06:56:48.118953Z",
     "start_time": "2024-04-21T06:56:48.065878Z"
    }
   },
   "cell_type": "code",
   "source": "cr = classification_report(y_test, y_pred, zero_division=0, output_dict=True)",
   "id": "c0d486c5c933a058",
   "outputs": [],
   "execution_count": 19
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-21T06:01:35.501181Z",
     "start_time": "2024-04-21T06:01:35.446446Z"
    }
   },
   "cell_type": "code",
   "source": "print(classification_report(y_test, y_pred, zero_division=0))",
   "id": "b4000b1ce55aa4ce",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00      4704\n",
      "           1       0.00      0.00      0.00      4756\n",
      "           2       0.00      0.00      0.00      4708\n",
      "           3       0.11      1.00      0.20      4590\n",
      "           4       0.00      0.00      0.00      4737\n",
      "           5       0.00      0.00      0.00      4616\n",
      "           6       0.00      0.00      0.00      4663\n",
      "           7       0.00      0.00      0.00      4657\n",
      "           8       0.00      0.00      0.00      4755\n",
      "\n",
      "    accuracy                           0.11     42186\n",
      "   macro avg       0.01      0.11      0.02     42186\n",
      "weighted avg       0.01      0.11      0.02     42186\n",
      "\n"
     ]
    }
   ],
   "execution_count": 15
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-21T06:01:36.815183Z",
     "start_time": "2024-04-21T06:01:36.790406Z"
    }
   },
   "cell_type": "code",
   "source": "cr[\"accuracy\"]",
   "id": "eafe800bd9358182",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.10880386858199402"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 16
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-21T06:57:13.738132Z",
     "start_time": "2024-04-21T06:57:13.711278Z"
    }
   },
   "cell_type": "code",
   "source": "type(cr[\"macro avg\"][\"precision\"])",
   "id": "9b61dce3acc10971",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "float"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 23
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
