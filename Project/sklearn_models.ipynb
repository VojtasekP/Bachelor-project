{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-05-01T08:44:18.266289Z",
     "start_time": "2024-05-01T08:44:18.240417Z"
    }
   },
   "source": [
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from torch import device\n",
    "from abc import ABC\n",
    "import warnings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.pipeline import Pipeline\n",
    "from signal_dataset import SignalDataset\n",
    "from sklearn.metrics import classification_report\n",
    "import re\n",
    "from pathlib import Path\n",
    "from sklearn.base import BaseEstimator, ClassifierMixin\n",
    "from sklearn.utils.validation import check_X_y\n",
    "import yaml\n",
    "import re\n",
    "from pathlib import Path\n",
    "import abc\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "import yaml\n",
    "from typing import Callable\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, classification_report\n",
    "from torch.utils.data import DataLoader, Dataset, random_split\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from tqdm import trange\n",
    "import seaborn as sns\n",
    "import networks\n",
    "from signal_dataset import SignalDataset\n",
    "import tsaug\n",
    "import torchaudio.transforms as T\n",
    "import torchaudio\n",
    "import librosa\n",
    "from IPython.display import Audio\n",
    "from matplotlib.patches import Rectangle"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "cell_type": "code",
   "source": [
    "sr = 1562500\n",
    "signal_data_dir = \"/mnt/home2/Motor_project/AE_PETR_motor/\"\n",
    "bin_setup = [{\"label\": i.stem, \"channels\": len(list(i.glob('*.bin'))), \"interval\": [0, 15 * sr], \"bin_path\": list(i.glob('*.bin'))[0]} for i in\n",
    "             Path(signal_data_dir).glob('WUP*') if re.search(r'\\d$', i.stem)]\n",
    "\n",
    "sd = SignalDataset(step=10000, window_size=10000, bin_setup=bin_setup, device=\"cpu\", source_dtype=\"float32\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-01T08:44:57.246877Z",
     "start_time": "2024-05-01T08:44:54.928613Z"
    }
   },
   "id": "612489b2d8ddfe1",
   "outputs": [],
   "execution_count": 18
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-01T08:44:21.376474Z",
     "start_time": "2024-05-01T08:44:21.374944Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "dbf08958e8ee34b8",
   "outputs": [],
   "execution_count": 9
  },
  {
   "cell_type": "code",
   "source": "train_data, test_data = random_split(sd, [0.8, 0.2])",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-01T08:44:57.280032Z",
     "start_time": "2024-05-01T08:44:57.248249Z"
    }
   },
   "id": "8eb748244b3a5544",
   "outputs": [],
   "execution_count": 19
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-28T11:32:42.496803Z",
     "start_time": "2024-04-28T11:32:42.463430Z"
    }
   },
   "cell_type": "code",
   "source": [
    "x = torch.from_numpy(train_data[2][0])\n",
    "x_reshape = torch.reshape(x, (1, -1))\n",
    "transform = T.Spectrogram(n_fft=200)\n",
    "spectrogram = transform(x)"
   ],
   "id": "9b84640b159e8a24",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "spectrogram.shape",
   "id": "918db6b0215bad55",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from torchaudio.utils import download_asset\n",
    "\n",
    "\n",
    "SAMPLE_SPEECH = download_asset(\"tutorial-assets/Lab41-SRI-VOiCES-src-sp0307-ch127535-sg0042.wav\")"
   ],
   "id": "7314e0475d408c49",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "SPEECH_WAVEFORM, SAMPLE_RATE = torchaudio.load(SAMPLE_SPEECH)",
   "id": "bf76d3985d92e6c8",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "spectrogram.shape",
   "id": "6c416b5794215cc5",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def plot_waveform(waveform, sr, title=\"Waveform\", ax=None):\n",
    "    waveform = waveform.numpy()\n",
    "\n",
    "    num_channels, num_frames = waveform.shape\n",
    "    time_axis = torch.arange(0, num_frames) / sr\n",
    "\n",
    "    if ax is None:\n",
    "        _, ax = plt.subplots(num_channels, 1)\n",
    "    ax.plot(time_axis, waveform[0], linewidth=1)\n",
    "    ax.grid(True)\n",
    "    ax.set_xlim([0, time_axis[-1]])\n",
    "    ax.set_title(title)"
   ],
   "id": "5679daf99906475a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def plot_spectrogram(specgram, title=None, ylabel=\"freq_bin\", ax=None):\n",
    "    if ax is None:\n",
    "        _, ax = plt.subplots(1, 1)\n",
    "    if title is not None:\n",
    "        ax.set_title(title)\n",
    "    ax.set_ylabel(ylabel)\n",
    "    ax.imshow(librosa.power_to_db(specgram), origin=\"lower\", aspect=\"auto\", interpolation=\"nearest\")"
   ],
   "id": "9f85cb2dad2936c7",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "fig, axs = plt.subplots(2, 1)\n",
    "plot_waveform(x_reshape, sr=sr, title=\"Original waveform\", ax=axs[0])\n",
    "plot_spectrogram(spectrogram[0], title=\"spectrogram\", ax=axs[1])\n",
    "plt.tight_layout()"
   ],
   "id": "e0c7393d6870a29e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-01T08:44:33.259086Z",
     "start_time": "2024-05-01T08:44:33.236027Z"
    }
   },
   "cell_type": "code",
   "source": "DEVICE = \"cuda\"",
   "id": "bd58c2ecf9e652aa",
   "outputs": [],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-01T08:44:23.775330Z",
     "start_time": "2024-05-01T08:44:23.742212Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class SignalModel:\n",
    "    def __init__(self, config_path: Path):\n",
    "        self.config_path = config_path\n",
    "        self._load_config()\n",
    "        self._model = self.init_model()\n",
    "        self._transform = self.init_transform()\n",
    "        self._load_config()\n",
    "\n",
    "    @abc.abstractmethod\n",
    "    def _load_config(self):\n",
    "        pass\n",
    "\n",
    "    @abc.abstractmethod\n",
    "    def init_model(self):\n",
    "        pass\n",
    "\n",
    "    @abc.abstractmethod  # raw outputs, targets\n",
    "    def evaluate(self, dataset: Dataset) -> (np.ndarray, np.ndarray):\n",
    "        pass\n",
    "\n",
    "    @abc.abstractmethod\n",
    "    def predict(self, x: np.ndarray) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Predicts the label of one or multiple signals.\n",
    "        \"\"\"\n",
    "        pass\n",
    "\n",
    "    @abc.abstractmethod\n",
    "    def save(self, path: Path):\n",
    "        pass\n",
    "\n",
    "    def init_transform(self) -> Callable:\n",
    "\n",
    "        def transform(x):\n",
    "            # return tsaug.AddNoise(scale=0.1).augment(x)\n",
    "            return T.Spectrogram(n_fft=200)(x)\n",
    "\n",
    "        return transform\n",
    "\n",
    "    # def _evaluate(self, x: np.ndarray) -> np.ndarray:\n",
    "    #     x = self._transform(x)\n",
    "    #     return self.inference(x)\n",
    "\n",
    "    def plot_confusion_matrix(self, y_pred: np.ndarray, y_true: np.ndarray):\n",
    "        class_num = 9  # in future will not be hard coded\n",
    "        cm = confusion_matrix(y_true, y_pred, labels=np.arange(class_num))\n",
    "        plt.figure(figsize=(10, 10))\n",
    "        plt.imshow(cm, cmap='Greens')\n",
    "        for i in range(class_num):\n",
    "            for j in range(class_num):\n",
    "                plt.text(j, i, cm[i, j], ha=\"center\", va=\"bottom\", color='gray')\n",
    "                plt.text(j, i, str(j), ha=\"center\", va=\"top\", color='gray')\n",
    "\n",
    "    def accuracy(self, y_pred: np.ndarray, y_true: np.ndarray) -> float:\n",
    "        return accuracy_score(y_true, y_pred)\n",
    "\n",
    "    def precision_and_recall(self, y_pred: np.ndarray, y_true: np.ndarray) -> (float, float):\n",
    "        cr = classification_report(y_true, y_pred, zero_division=0, output_dict=True)\n",
    "        return cr[\"macro avg\"][\"precision\"], cr[\"macro avg\"][\"recall\"]\n",
    "\n",
    "    def classification_report(self, y_pred: np.ndarray, y_true: np.ndarray) -> dict:\n",
    "        return classification_report(y_true, y_pred, zero_division=0, output_dict=True)"
   ],
   "id": "523af06032ef9686",
   "outputs": [],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-01T08:44:24.628323Z",
     "start_time": "2024-05-01T08:44:24.597454Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class SklearnModel(SignalModel, ABC):\n",
    "    \n",
    "    def __init__(self, config_path: Path):\n",
    "        super().__init__(config_path)\n",
    "\n",
    "    def _load_config(self):\n",
    "        with self.config_path.open(mode=\"r\") as yaml_file:\n",
    "            self.config = yaml.load(yaml_file, Loader=yaml.SafeLoader)\n",
    "            self.model_config = self.config[\"model\"]\n",
    "\n",
    "    def init_model(self):\n",
    "        match self.model_config[\"type\"]:\n",
    "            case \"DummyClassifier\":\n",
    "                return DummyClassifier()\n",
    "            case \"RandomForestClassifier\":\n",
    "                return RandomForestClassifier()\n",
    "\n",
    "    def train(self, train_dataset: Dataset, test_dataset: Dataset) -> None:\n",
    "        x_train = np.asarray([data[0] for data in train_dataset])\n",
    "        x_train = self._transform(x_train)\n",
    "        y_train = np.asarray([data[1] for data in train_dataset])\n",
    "        self._model.fit(x_train, y_train)\n",
    "\n",
    "    def predict(self, x: np.ndarray) -> np.ndarray:\n",
    "        return self._model.predict(x)"
   ],
   "id": "996245ffe884c948",
   "outputs": [],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-01T08:44:25.464650Z",
     "start_time": "2024-05-01T08:44:25.428934Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class NeuroNet(SignalModel, ABC):\n",
    "\n",
    "    def __init__(self, config_path: Path, tensorboard: bool = False, testing_loss: bool = False):\n",
    "        super().__init__(config_path)\n",
    "        self.tensorboard = tensorboard\n",
    "        self.testing_loss = testing_loss\n",
    "        self._model.to(DEVICE)\n",
    "\n",
    "        self.criterion = nn.CrossEntropyLoss()\n",
    "        self.writer = SummaryWriter(\n",
    "            comment=f\"_{config_path.stem}_{self.config['eval_params']['batch_size']}\")\n",
    "\n",
    "        self.train_loss = []\n",
    "        self.val_loss = []\n",
    "        self.val_accuracy = []\n",
    "        self.total_batch_id = 1\n",
    "        self.epoch_trained = 0\n",
    "        self.train_set: bool\n",
    "\n",
    "    def _load_config(self) -> None:\n",
    "        with self.config_path.open(mode=\"r\") as yaml_file:\n",
    "            self.config = yaml.load(yaml_file, Loader=yaml.SafeLoader)\n",
    "            self.model_config = self.config[\"model\"]\n",
    "\n",
    "        if isinstance(self.model_config[\"kwargs\"][\"layers\"], list):\n",
    "            self.layers_configs = []\n",
    "            for layer_config in self.model_config[\"kwargs\"][\"layers\"]:\n",
    "                self.layers_configs.append(layer_config)\n",
    "        else:\n",
    "            self.layers_configs = {}\n",
    "            for name, kwargs in self.model_config[\"kwargs\"][\"layers\"].items():\n",
    "                self.layers_configs[name] = kwargs\n",
    "\n",
    "    def init_model(self):\n",
    "        # TODO: make in_channels as parameter\n",
    "        match self.model_config[\"type\"]:\n",
    "            case \"MLP\":\n",
    "                return networks.MLP(self.layers_configs)\n",
    "            case \"Inception time\" | \"Inception\" | \"Inception_time\":\n",
    "                return networks.InceptionTime(self.layers_configs)\n",
    "            case \"LSTM\" | \"GRU\":\n",
    "                # return networks.RNN(self.layers_configs)\n",
    "                return networks.RNN(self.layers_configs, attention=self.model_config[\"attention\"])\n",
    "            case \"CNN\":\n",
    "                return networks.CNN(self.layers_configs)\n",
    "            case \"LSTM-FCN\" | \"lstm_fcn\":\n",
    "                return networks.RnnFcn(self.layers_configs)\n",
    "\n",
    "    def train(self, train_dataset: Dataset, test_dataset: Dataset) -> None:\n",
    "\n",
    "        self._load_config()\n",
    "\n",
    "        optimizer = optim.Adam(self._model.parameters(), self.config[\"lr\"])\n",
    "        scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer,\n",
    "                                                               T_max=self.config[\"training_params\"][\n",
    "                                                                   \"epoch_num\"])\n",
    "        g = torch.Generator().manual_seed(0)\n",
    "        train_dataloader = DataLoader(train_dataset,\n",
    "                                      **self.config[\"training_params\"].get(\"dataloader_params\", {}), generator=g)\n",
    "        test_dataloader = DataLoader(test_dataset, **self.config[\"eval_params\"])\n",
    "\n",
    "        epochs = trange(self.config[\"training_params\"][\"epoch_num\"], ncols=100)  # , desc='Epoch #', leave=True)\n",
    "        running_loss = 0\n",
    "\n",
    "        best_val_loss = 10000\n",
    "        for epoch in epochs:\n",
    "            # for epoch in range(self.config[\"training_params\"][\"epoch_num\"]):\n",
    "            running_val_loss = 0\n",
    "            for i, (inputs, targets) in enumerate(train_dataloader):\n",
    "                self._model.train()\n",
    "                inputs = self._transform(inputs)\n",
    "                # inputs = torch.from_numpy(self._transform(inputs.numpy()))\n",
    "                inputs, targets = inputs.to(DEVICE), targets.to(DEVICE)\n",
    "                optimizer.zero_grad()\n",
    "  \n",
    "                outputs = self._model(inputs)\n",
    "                loss = self.criterion(outputs, targets)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                # calc of the loss, 4 times per epoch\n",
    "                running_loss += loss.item()\n",
    "                # TODO: use deque instead of lists\n",
    "                if (i + 1) % 50 == 0:\n",
    "                    avg_loss = running_loss / 50\n",
    "                    self.train_loss.append(avg_loss)\n",
    "                    self.writer.add_scalar(tag='Loss/train', scalar_value=avg_loss, global_step=self.total_batch_id)\n",
    "                    running_loss = 0\n",
    "\n",
    "                if self.tensorboard:\n",
    "                    self.train_set = False\n",
    "                    self.calculate_metrics(test_dataset)\n",
    "                    # self.train_set = True\n",
    "                    # self.calculate_metrics(train_dataset)\n",
    "\n",
    "                epochs.set_description(f\"Epoch #{self.epoch_trained + 1}\")\n",
    "                self.total_batch_id += 1\n",
    "\n",
    "            # this part of the code serves as check if tensorboard is working correctly\n",
    "            if self.testing_loss:\n",
    "                j = 0\n",
    "                for i, (val_inputs, val_targets) in enumerate(test_dataloader):\n",
    "                    self._model.eval()\n",
    "                    with torch.no_grad():\n",
    "                        val_inputs, val_targets = val_inputs.to(DEVICE), val_targets.to(DEVICE)\n",
    "                        val_outputs = self.infer(val_inputs)\n",
    "                        val_loss = self.criterion(val_outputs, val_targets)\n",
    "                        running_val_loss += val_loss\n",
    "                        j += 1\n",
    "                    avg_val_loss = running_val_loss / (j + 1)\n",
    "                print(' LOSS train: {},  valid: {}'.format(avg_loss, avg_val_loss))\n",
    "\n",
    "            last_lr = scheduler.get_last_lr()[0]  # get the last learning rate\n",
    "            self.writer.add_scalar(tag='learning rate', scalar_value=last_lr, global_step=self.epoch_trained)\n",
    "            self.epoch_trained += 1\n",
    "            scheduler.step()  #\n",
    "\n",
    "            # epochs.refresh()\n",
    "            #\n",
    "            # self.eval_model(testing_data, writer, )\n",
    "\n",
    "            self.writer.close()\n",
    "\n",
    "    def predict(self, x: np.ndarray) -> np.ndarray:\n",
    "        self._model.eval()\n",
    "        with torch.no_grad():\n",
    "            x = torch.from_numpy(x).to(DEVICE)\n",
    "            if x.ndim == 1:\n",
    "                x = torch.reshape(x, (1, -1))\n",
    "            output = self._model(x)\n",
    "            return torch.argmax(output, dim=1).cpu().numpy()\n",
    "\n",
    "    def calculate_metrics(self, dataset: Dataset) -> None:\n",
    "\n",
    "        if (self.total_batch_id % self.config[\"tensorboard_params\"][\"confusion_matrix\"] == 0 or\n",
    "                self.total_batch_id % self.config[\"tensorboard_params\"][\"accuracy\"] == 0 or\n",
    "                self.total_batch_id % self.config[\"tensorboard_params\"][\"validation_loss\"] == 0):\n",
    "\n",
    "            if self.train_set:\n",
    "                dataloader = DataLoader(dataset, **self.config[\"training_params\"].get(\"dataloader_params\", {}))\n",
    "            else:\n",
    "                dataloader = DataLoader(dataset, **self.config[\"eval_params\"])\n",
    "\n",
    "            # concat of tensors is faster than extending lists\n",
    "            tag = \"train\" if self.train_set else \"val\"\n",
    "            # TODO: try append and then torch.cat\n",
    "            self._model.eval()\n",
    "            with torch.no_grad():\n",
    "                outputs = torch.empty(size=(0, 9), dtype=torch.float32, device=DEVICE)\n",
    "                targets = torch.empty(size=(0, 1), dtype=torch.long, device=DEVICE).flatten()\n",
    "                for i, (input, target) in enumerate(dataloader):\n",
    "                    input = self._transform(input)\n",
    "                    input, target = input.to(DEVICE), target.to(DEVICE)\n",
    "                    output = self._model(input)\n",
    "                    outputs.append(output)\n",
    "                    targets = torch.cat((targets, target), dim=0)\n",
    "                if not self.train_set and self.total_batch_id % self.config[\"tensorboard_params\"][\n",
    "                    \"validation_loss\"] == 0:\n",
    "                    val_loss = self.criterion(outputs, targets)\n",
    "                    self.val_loss.append(val_loss)\n",
    "                self.writer.add_scalar(tag=f'Loss/val', scalar_value=val_loss, global_step=self.total_batch_id)\n",
    "\n",
    "            class_num = 9\n",
    "\n",
    "            outputs, targets = np.asarray(outputs.cpu()), np.asarray(targets.cpu())\n",
    "            predictions = np.argmax(outputs, axis=1)  # makes the correct predictions\n",
    "\n",
    "            if self.total_batch_id % self.config[\"tensorboard_params\"][\"accuracy\"] == 0:\n",
    "                # cr = classification_report(targets, predictions, labels=np.arange(class_num), output_dict=True,\n",
    "                #                            zero_division=0)\n",
    "                # self.writer.add_scalar(tag=f'Precision/{tag}',\n",
    "                #                        scalar_value=cr[\"macro avg\"][\"precision\"], global_step=self.total_batch_id)\n",
    "                # self.writer.add_scalar(tag=f'Recall/{tag}',\n",
    "                #                        scalar_value=cr[\"macro avg\"]['recall'], global_step=self.total_batch_id)\n",
    "                # self.writer.add_scalar(tag=f'F1-score/{tag}',\n",
    "                #                        scalar_value=cr[\"macro avg\"][\"f1-score\"], global_step=self.total_batch_id)\n",
    "                accuracy = accuracy_score(predictions, targets)\n",
    "                if not self.train_set:\n",
    "                    self.val_accuracy.append(accuracy)\n",
    "                self.writer.add_scalar(tag=f'Accuracy/{tag}',\n",
    "                                       scalar_value=accuracy, global_step=self.total_batch_id)\n",
    "\n",
    "\n",
    "\n",
    "            if self.total_batch_id % self.config[\"tensorboard_params\"][\"confusion_matrix\"] == 0:\n",
    "                plt.figure(figsize=(12, 7))\n",
    "                cm = confusion_matrix(targets, predictions, labels=np.arange(class_num))\n",
    "                df_cm = pd.DataFrame(cm / np.sum(cm, axis=1)[:, None], index=[i for i in range(class_num)],\n",
    "                                     columns=[i for i in range(class_num)])\n",
    "                sns_cm = sns.heatmap(df_cm, annot=True, fmt=\".1f\")\n",
    "                sns_cm.set_ylim(9.5, -0.5)\n",
    "                self.writer.add_figure(tag=f\"Confusion matrix/{tag}\",\n",
    "                                       figure=sns_cm.get_figure(),\n",
    "                                       global_step=self.total_batch_id)\n",
    "\n",
    "    def save(self, path: str) -> None:\n",
    "        torch.save(self._model, Path(path))\n",
    "\n",
    "    def close_writer(self):\n",
    "        self.writer.close()\n",
    "        print(\"Tensorboard summary writer is closed\")"
   ],
   "id": "ced38c2cfb5a9fa",
   "outputs": [],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-01T08:45:01.348226Z",
     "start_time": "2024-05-01T08:45:01.032113Z"
    }
   },
   "cell_type": "code",
   "source": [
    "neuro_net = NeuroNet(Path(\"nn_yaml_configs/CNN_spec.yaml\"), tensorboard=True)\n",
    "random_forest = SklearnModel(Path(\"non_dl_yaml_configs/random_forest_classifier.yaml\"))\n",
    "dummy_classifier = SklearnModel(Path(\"non_dl_yaml_configs/dummy_classifier.yaml\"))\n"
   ],
   "id": "b401eec108a4a504",
   "outputs": [],
   "execution_count": 20
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-01T08:45:17.938660Z",
     "start_time": "2024-05-01T08:45:01.899939Z"
    }
   },
   "cell_type": "code",
   "source": "neuro_net.train(train_data, test_data)\n",
   "id": "f3e2c37ad89f1062",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #2: 100%|███████████████████████████████████████████████████████| 2/2 [00:15<00:00,  7.61s/it]\n"
     ]
    }
   ],
   "execution_count": 21
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "neuro_net.close_writer()",
   "id": "ab7131c26bcbedd3",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-01T08:45:41.430684Z",
     "start_time": "2024-05-01T08:45:40.684247Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "test_dataloader = DataLoader(test_data, batch_size=512, shuffle=False)\n",
    "models = {\"neuro_net\": neuro_net, \"dummy\": dummy_classifier}\n",
    "torch.cuda.empty_cache()\n",
    "# print(np.equal(neuro_net.targets, y_test))\n",
    "\n",
    "for name, model in models.items():\n",
    "    outputs = np.empty((0,), dtype=np.float32)\n",
    "    targets = np.empty((0,), dtype=np.longdouble).flatten()\n",
    "    for i, (input, target) in enumerate(test_dataloader):\n",
    "        input, target = input.numpy(), target.numpy()\n",
    "        output = model.predict(input)\n",
    "        outputs = np.concatenate((outputs, output), axis=0)\n",
    "        targets = np.concatenate((targets, target), axis=0)\n",
    "    model.plot_confusion_matrix(outputs, targets)"
   ],
   "id": "2d3d50d22ef088e0",
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Given groups=1, weight of size [64, 1, 5, 5], expected input[1, 512, 1, 10000] to have 1 channels, but got 512 channels instead",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mRuntimeError\u001B[0m                              Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[22], line 11\u001B[0m\n\u001B[1;32m      9\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m i, (\u001B[38;5;28minput\u001B[39m, target) \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28menumerate\u001B[39m(test_dataloader):\n\u001B[1;32m     10\u001B[0m     \u001B[38;5;28minput\u001B[39m, target \u001B[38;5;241m=\u001B[39m \u001B[38;5;28minput\u001B[39m\u001B[38;5;241m.\u001B[39mnumpy(), target\u001B[38;5;241m.\u001B[39mnumpy()\n\u001B[0;32m---> 11\u001B[0m     output \u001B[38;5;241m=\u001B[39m model\u001B[38;5;241m.\u001B[39mpredict(\u001B[38;5;28minput\u001B[39m)\n\u001B[1;32m     12\u001B[0m     outputs \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39mconcatenate((outputs, output), axis\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m0\u001B[39m)\n\u001B[1;32m     13\u001B[0m     targets \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39mconcatenate((targets, target), axis\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m0\u001B[39m)\n",
      "Cell \u001B[0;32mIn[12], line 129\u001B[0m, in \u001B[0;36mNeuroNet.predict\u001B[0;34m(self, x)\u001B[0m\n\u001B[1;32m    127\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m x\u001B[38;5;241m.\u001B[39mndim \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m1\u001B[39m:\n\u001B[1;32m    128\u001B[0m     x \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mreshape(x, (\u001B[38;5;241m1\u001B[39m, \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m))\n\u001B[0;32m--> 129\u001B[0m output \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_model(x)\n\u001B[1;32m    130\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m torch\u001B[38;5;241m.\u001B[39margmax(output, dim\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1\u001B[39m)\u001B[38;5;241m.\u001B[39mcpu()\u001B[38;5;241m.\u001B[39mnumpy()\n",
      "File \u001B[0;32m/mnt/home2/anaconda3/envs/t2/lib/python3.12/site-packages/torch/nn/modules/module.py:1511\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1509\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[1;32m   1510\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m-> 1511\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[0;32m/mnt/home2/anaconda3/envs/t2/lib/python3.12/site-packages/torch/nn/modules/module.py:1520\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1515\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1516\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1517\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[1;32m   1518\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1519\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1520\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m forward_call(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[1;32m   1522\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m   1523\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "File \u001B[0;32m~/Documents/bachelor_project/Project/networks.py:64\u001B[0m, in \u001B[0;36mCNN.forward\u001B[0;34m(self, x)\u001B[0m\n\u001B[1;32m     62\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mforward\u001B[39m(\u001B[38;5;28mself\u001B[39m, x):\n\u001B[0;32m---> 64\u001B[0m     x \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mlayers(x)\n\u001B[1;32m     66\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m x\n",
      "File \u001B[0;32m/mnt/home2/anaconda3/envs/t2/lib/python3.12/site-packages/torch/nn/modules/module.py:1511\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1509\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[1;32m   1510\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m-> 1511\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[0;32m/mnt/home2/anaconda3/envs/t2/lib/python3.12/site-packages/torch/nn/modules/module.py:1520\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1515\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1516\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1517\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[1;32m   1518\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1519\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1520\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m forward_call(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[1;32m   1522\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m   1523\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "File \u001B[0;32m/mnt/home2/anaconda3/envs/t2/lib/python3.12/site-packages/torch/nn/modules/container.py:217\u001B[0m, in \u001B[0;36mSequential.forward\u001B[0;34m(self, input)\u001B[0m\n\u001B[1;32m    215\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mforward\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;28minput\u001B[39m):\n\u001B[1;32m    216\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m module \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m:\n\u001B[0;32m--> 217\u001B[0m         \u001B[38;5;28minput\u001B[39m \u001B[38;5;241m=\u001B[39m module(\u001B[38;5;28minput\u001B[39m)\n\u001B[1;32m    218\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28minput\u001B[39m\n",
      "File \u001B[0;32m/mnt/home2/anaconda3/envs/t2/lib/python3.12/site-packages/torch/nn/modules/module.py:1511\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1509\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[1;32m   1510\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m-> 1511\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[0;32m/mnt/home2/anaconda3/envs/t2/lib/python3.12/site-packages/torch/nn/modules/module.py:1520\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1515\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1516\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1517\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[1;32m   1518\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1519\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1520\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m forward_call(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[1;32m   1522\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m   1523\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "File \u001B[0;32m/mnt/home2/anaconda3/envs/t2/lib/python3.12/site-packages/torch/nn/modules/conv.py:460\u001B[0m, in \u001B[0;36mConv2d.forward\u001B[0;34m(self, input)\u001B[0m\n\u001B[1;32m    459\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mforward\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;28minput\u001B[39m: Tensor) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Tensor:\n\u001B[0;32m--> 460\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_conv_forward(\u001B[38;5;28minput\u001B[39m, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mweight, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mbias)\n",
      "File \u001B[0;32m/mnt/home2/anaconda3/envs/t2/lib/python3.12/site-packages/torch/nn/modules/conv.py:456\u001B[0m, in \u001B[0;36mConv2d._conv_forward\u001B[0;34m(self, input, weight, bias)\u001B[0m\n\u001B[1;32m    452\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mpadding_mode \u001B[38;5;241m!=\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mzeros\u001B[39m\u001B[38;5;124m'\u001B[39m:\n\u001B[1;32m    453\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m F\u001B[38;5;241m.\u001B[39mconv2d(F\u001B[38;5;241m.\u001B[39mpad(\u001B[38;5;28minput\u001B[39m, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_reversed_padding_repeated_twice, mode\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mpadding_mode),\n\u001B[1;32m    454\u001B[0m                     weight, bias, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mstride,\n\u001B[1;32m    455\u001B[0m                     _pair(\u001B[38;5;241m0\u001B[39m), \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdilation, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mgroups)\n\u001B[0;32m--> 456\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m F\u001B[38;5;241m.\u001B[39mconv2d(\u001B[38;5;28minput\u001B[39m, weight, bias, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mstride,\n\u001B[1;32m    457\u001B[0m                 \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mpadding, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdilation, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mgroups)\n",
      "\u001B[0;31mRuntimeError\u001B[0m: Given groups=1, weight of size [64, 1, 5, 5], expected input[1, 512, 1, 10000] to have 1 channels, but got 512 channels instead"
     ]
    }
   ],
   "execution_count": 22
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-01T08:34:42.317586Z",
     "start_time": "2024-05-01T08:34:42.293039Z"
    }
   },
   "cell_type": "code",
   "source": [
    "final = []\n",
    "a = torch.rand(2,1)\n",
    "b = torch.rand(2,1)\n",
    "final.extend(a)\n",
    "final.extend(b)"
   ],
   "id": "3939a832cfd7f0f5",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-01T08:35:24.620489Z",
     "start_time": "2024-05-01T08:35:24.588603Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "a = [torch.rand(20,1,500) for i in range(20)]\n",
    "torch.cat(a).shape"
   ],
   "id": "66da1caa853ad51d",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([400, 1, 500])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# TODO: plot confusion matrix for multiple models\n",
    "# TODO: plot matrix for num_of_samples x channels. Probability distributions in columns.\n",
    "# TODO: Noise, scaling(0.2,5)\n",
    "# TODO: MEL spectrogram (for music)\n",
    "# TODO: ml models: HIVE-COTE, Linear model, Random forest"
   ],
   "id": "fb71c221d9dc6449"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
