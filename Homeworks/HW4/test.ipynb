{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1e76f551-0642-4e83-b12f-99290beba835",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7f4a00a0ccb0>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import yaml\n",
    "from icecream import ic\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import random_split\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "\n",
    "DEVICE = 'cuda'\n",
    "torch.manual_seed(22)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "521d7e28-b62f-4c4d-9161-39e87bf0ada5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SineDataset(Dataset):\n",
    "    \"\"\"Face Landmarks dataset.\"\"\"\n",
    "\n",
    "    def __init__(self, data_count):\n",
    "        self.freq = 10*torch.rand(size=(data_count, 1), device=DEVICE) + 1\n",
    "        \n",
    "        random_uniform_shift = 10*torch.rand(size=(data_count, 1), device=DEVICE)\n",
    "        random_normal_shift = torch.normal(0, 1, size=(1, 1), device=DEVICE)\n",
    "        \n",
    "        self.points = torch.arange(0,6,1/40, device=DEVICE).repeat(data_count, 1)  + random_uniform_shift\n",
    "        self.phase = torch.normal(0, 5, size=(data_count, 1), device=DEVICE)\n",
    "        self.amplitude = (self.points[0] - random_uniform_shift[0])**2 \n",
    "        # print(self.amplitude)\n",
    "        self.data_matrix = torch.sin(self.points * self.freq + self.phase)\n",
    "        self.data_matrix_without_noise = torch.sin(self.points * self.freq + self.phase)\n",
    "        for i in range(data_count):\n",
    "            if random.random() < 0.3:\n",
    "                self.amplitude = torch.flip(self.amplitude, dims=(-1,))\n",
    "                random_noise = (self.amplitude+1)*torch.normal(0, 1, size=(1, len(self.data_matrix[0])), device=DEVICE)\n",
    "                self.data_matrix_without_noise[i] = self.amplitude*self.data_matrix[i]\n",
    "                self.data_matrix[i] = self.amplitude*self.data_matrix[i] + random_noise\n",
    "            elif 0.3<=random.random() <0.7:\n",
    "                random_noise = (self.amplitude+1)*torch.normal(0, 1, size=(1, len(self.data_matrix[0])), device=DEVICE)\n",
    "                self.data_matrix_without_noise[i] = self.amplitude*self.data_matrix[i]\n",
    "                self.data_matrix[i] = self.amplitude*self.data_matrix[i] + random_noise               \n",
    "            else:\n",
    "                random_noise = torch.normal(0, 1, size=(1, len(self.data_matrix[0])), device=DEVICE)\n",
    "                self.data_matrix_without_noise[i] = self.data_matrix[i]\n",
    "                self.data_matrix[i] = self.data_matrix[i] + random_noise\n",
    "    def __len__(self):\n",
    "        return len(self.freq)\n",
    "        \n",
    "    def __num__(self):\n",
    "        return\n",
    "    def __getitem__(self, idx):\n",
    "        return self.data_matrix[idx], self.freq[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ba1effa-7c25-4c48-a2f3-d7222b62e2d5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6e50326c-08db-40ca-a53b-2d135114f54a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNN_CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.rnn = nn.LSTM(input_size=240, hidden_size=64, num_layers=1, batch_first = True)\n",
    "        self.bn = nn.BatchNorm1d(num_features=1)\n",
    "        self.conv = nn.Conv1d(in_channels=1, out_channels=1, kernel_size=6, stride=2)\n",
    "        self.lin1 = nn.Linear(30, 1)\n",
    "        self.lin2 = nn.Linear(240, 30)\n",
    "    def forward(self, x):\n",
    "        residual = self.lin2(x)\n",
    "        out = torch.unsqueeze(x, 1)\n",
    "        # out, (h0, c0) = self.rnn(out)\n",
    "        # out = self.bn(out)\n",
    "        # out = torch.permute(out, (0, 2, 1))\n",
    "        out = F.relu(self.conv(x))\n",
    "        # out = self.bn(out)\n",
    "        out = torch.squeeze(out, 1)\n",
    "        out = out + residual\n",
    "        out = F.relu(self.lin1(out))\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "93f19b9a-4b89-4a23-b431-9017d36256da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nBlock1:\\n    conv1d (krnl_sz = 3)\\n    bn (on out_channels)\\n    relu after batchnorm \\n    conv1d\\n    bn \\nBlock2:\\n    if you have different stride more than 2 or in_channels != out_channels you have to do convolution on your shortcut to maintain dimensionality with kernel_size = 1 so basically dense layer with multiplying channels\\n    \\nAdd the outputs from 2 blocks together\\n'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Block1:\n",
    "    conv1d (krnl_sz = 3)\n",
    "    bn (on out_channels)\n",
    "    relu after batchnorm \n",
    "    conv1d\n",
    "    bn \n",
    "Block2:\n",
    "    if you have different stride more than 2 or in_channels != out_channels you have to do convolution on your shortcut to maintain dimensionality with kernel_size = 1 so basically dense layer with multiplying channels\n",
    "    \n",
    "Add the outputs from 2 blocks together\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2f2a1257-fa72-44f8-82b9-0498e62a9806",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResidualBlock(nn.Module):\n",
    "    def __init__(self, in_channels: int, out_channels: int, stride=1):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv1d(in_channels, out_channels, kernel_size=3, stride=stride, padding=1)\n",
    "        self.bn = nn.BatchNorm1d(out_channels)\n",
    "        \n",
    "        self.conv2 = nn.Conv1d(out_channels, out_channels, kernel_size = 3, stride = 1, padding=1) \n",
    "        if stride != 1 or in_channels != out_channels:\n",
    "            self.shortcut = nn.Sequential(\n",
    "                nn.Conv1d(in_channels, out_channels, kernel_size=1, stride=stride),\n",
    "                nn.BatchNorm1d(out_channels)\n",
    "            )\n",
    "        else:\n",
    "            self.shortcut=nn.Sequential()\n",
    "            \n",
    "    def forward(self, x):\n",
    "        # print(x.shape)\n",
    "        out = self.conv1(x)\n",
    "        # print(f\"first {out.shape}\")\n",
    "        out = F.relu((self.bn(out)))\n",
    "        out = self.conv2(out)\n",
    "        # print(f\"second {out.shape}\")\n",
    "        x = self.shortcut(x)\n",
    "        # print(f\"third {x.shape}\")\n",
    "        out += x\n",
    "        out = F.relu(self.bn(out))\n",
    "        # print(f\"forth {out.shape}\")\n",
    "        return out       \n",
    "                               \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b6614d30-0d58-456c-8d62-9a03c1fed0ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nso you make stack these Residual blocks successively you choose how many blocks you connect in num_blocks\\n'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "so you make stack these Residual blocks successively you choose how many blocks you connect in num_blocks\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1d34fdac-600e-40d7-929d-09d4120f5cec",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResNet(nn.Module):\n",
    "    def __init__(self, num_blocks: int, out_channels: int):\n",
    "        super().__init__()\n",
    "        self.in_channels = 1 # You can adjust the initial number of channels\n",
    "        self.rnn = nn.LSTM(input_size=240, hidden_size=240, num_layers=2, batch_first=True )\n",
    "        self.conv = nn.Conv1d(1, self.in_channels, kernel_size=7, padding=3)\n",
    "        self.bn = nn.BatchNorm1d(self.in_channels)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.layer1 = self.make_layer(ResidualBlock, num_blocks, out_channels)\n",
    "        self.global_avg_pooling = nn.AdaptiveAvgPool1d(1)\n",
    "        self.fc = nn.Linear(out_channels, 1)\n",
    "        self.attention = nn.Linear(240, 240)\n",
    "    def make_layer(self, block, num_blocks, out_channels):\n",
    "        layers = []\n",
    "        for _ in range(num_blocks):\n",
    "            layers.append(block(self.in_channels, out_channels))\n",
    "            self.in_channels = out_channels\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.unsqueeze(x, 1)\n",
    "        x = F.relu(self.bn(self.conv(x)))\n",
    "        x = self.bn(x)\n",
    "        x = self.layer1(x)\n",
    "        out, (h0,c0) = self.rnn(x)\n",
    "        attention_weights = F.softmax(self.attention(out), dim=-1)\n",
    "        out = torch.sum(attention_weights * out, dim=1)\n",
    "        out = self.global_avg_pooling(out)\n",
    "        out = torch.squeeze(out, 1)\n",
    "        out = self.fc(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d65c8f9f-6f3d-4994-b6b3-d2b8b295ff90",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN_RNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.bn1 = nn.BatchNorm1d(118)\n",
    "        self.conv = nn.Conv1d(in_channels=1, out_channels=1, kernel_size=5, stride=2)\n",
    "        self.rnn = nn.LSTM(input_size=118, hidden_size=64, num_layers=1, batch_first = True, bidirectional=True)\n",
    "        self.conv2 = nn.Conv1d(in_channels=1, out_channels=1, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv3 = nn.Conv1d(in_channels=1, out_channels=1, kernel_size=20, stride=8)\n",
    "        self.lin1 = nn.Linear(128, 64)\n",
    "        self.lin2 = nn.Linear(64,1)\n",
    "    def forward(self, x):\n",
    "        out = torch.unsqueeze(x, 1)\n",
    "        out = F.relu(self.conv(out))\n",
    "        # self.bn1 = nn.BatchNorm1d(118)\n",
    "        out, (h0, c0) = self.rnn(out)\n",
    "        out = self.conv2(out)\n",
    "        out = torch.squeeze(out, 1)\n",
    "        out = F.relu(self.lin1(out))\n",
    "        out = F.relu(self.lin2(out))\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a53b42b1-55d1-4282-b914-7c68264e8e74",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNN_CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.rnn = nn.LSTM(input_size=240, hidden_size=64, num_layers=1, batch_first=True)\n",
    "        self.bn = nn.BatchNorm1d(num_features=1)\n",
    "        self.conv = nn.Conv1d(in_channels=1, out_channels=1, kernel_size=6, stride=2)\n",
    "        self.lin1 = nn.Linear(240, 30)\n",
    "        self.lin2 = nn.Linear(30, 1)\n",
    "    def forward(self, x):\n",
    "        residual = self.lin1(x)\n",
    "        out = torch.unsqueeze(x, 1)\n",
    "        out, (h0, c0) = self.rnn(out)\n",
    "        out = self.bn(out)\n",
    "        # out = torch.permute(out, (0, 2, 1))\n",
    "        out = F.relu(self.conv(out))\n",
    "        # out = self.bn(out)\n",
    "        out = torch.squeeze(out, 1)\n",
    "        out = out + residual\n",
    "        out = F.relu(self.lin2(out))\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fce458df-e52e-4b8e-8a64-d1499b35ad9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 1/ 200:   0%|                                                                                                                                                                                                                                                 | 0/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "mat1 and mat2 shapes cannot be multiplied (1x64 and 1x1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 65\u001b[0m\n\u001b[1;32m     61\u001b[0m train_data, test_data \u001b[38;5;241m=\u001b[39m random_split(dataset, [\u001b[38;5;241m64\u001b[39m, \u001b[38;5;241m64\u001b[39m])\n\u001b[1;32m     63\u001b[0m neuro_net \u001b[38;5;241m=\u001b[39m NeuroNet()\n\u001b[0;32m---> 65\u001b[0m \u001b[43mneuro_net\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_data\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[10], line 30\u001b[0m, in \u001b[0;36mNeuroNet.train_model\u001b[0;34m(self, training_data, testing_data)\u001b[0m\n\u001b[1;32m     28\u001b[0m inputs, targets \u001b[38;5;241m=\u001b[39m inputs\u001b[38;5;241m.\u001b[39mto(DEVICE), targets\u001b[38;5;241m.\u001b[39mto(DEVICE)\n\u001b[1;32m     29\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m---> 30\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     31\u001b[0m loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcriterion(outputs, targets)\n\u001b[1;32m     32\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n",
      "File \u001b[0;32m~/anaconda3/envs/t2/lib/python3.11/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/t2/lib/python3.11/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[7], line 30\u001b[0m, in \u001b[0;36mResNet.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     28\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mglobal_avg_pooling(out)\n\u001b[1;32m     29\u001b[0m out \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39msqueeze(out, \u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m---> 30\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     31\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m out\n",
      "File \u001b[0;32m~/anaconda3/envs/t2/lib/python3.11/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/t2/lib/python3.11/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/t2/lib/python3.11/site-packages/torch/nn/modules/linear.py:114\u001b[0m, in \u001b[0;36mLinear.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 114\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: mat1 and mat2 shapes cannot be multiplied (1x64 and 1x1)"
     ]
    }
   ],
   "source": [
    "class NeuroNet:\n",
    "    def __init__(self):\n",
    "        self.model = self.build_model()\n",
    "        self.model.to('cuda')\n",
    "        self.optimizer = optim.Adam(self.model.parameters(), lr=0.001)\n",
    "        self.scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(self.optimizer, 10)\n",
    "        self.criterion = nn.MSELoss()\n",
    "        self.history = []\n",
    "        self.mse_avg = 0\n",
    "        \n",
    "\n",
    "    def build_model(self):\n",
    "            return ResNet(num_blocks=2,out_channels=1)\n",
    "\n",
    "\n",
    "    def train_model(self, training_data: Dataset, testing_data: Dataset):\n",
    "        writer = SummaryWriter(comment=\"_ResNet\")\n",
    "        step = 0\n",
    "        epoch_num = 200\n",
    "        train_dataloader = DataLoader(training_data, batch_size=64, shuffle=True)\n",
    "        test_dataloader = DataLoader(testing_data, batch_size=64, shuffle=True)\n",
    "\n",
    "        for epoch in range(epoch_num):\n",
    "            self.model.train()\n",
    "            self.history = []\n",
    "            for batch_id, (inputs, targets) in enumerate(\n",
    "                    tqdm(train_dataloader, desc=f'epoch {epoch + 1}/ {epoch_num}')):\n",
    "                inputs, targets = inputs.to(DEVICE), targets.to(DEVICE)\n",
    "                self.optimizer.zero_grad()\n",
    "                outputs = self.model(inputs)\n",
    "                loss = self.criterion(outputs, targets)\n",
    "                loss.backward()\n",
    "                self.optimizer.step()\n",
    "                writer.add_scalar('Training Loss', loss, global_step=step)\n",
    "                step += 1\n",
    "\n",
    "            self.model.eval()\n",
    "            with torch.no_grad():\n",
    "                for batch_id, (inputs, targets) in enumerate(test_dataloader):\n",
    "                    outputs = self.model(inputs)\n",
    "                    mse = np.mean((outputs.detach().cpu().numpy() - targets.detach().cpu().numpy()) ** 2)\n",
    "                    self.history.append(mse)\n",
    "                    self.mse_avg = sum(self.history) / len(self.history)\n",
    "                    writer.add_scalar('validation loss', self.mse_avg, global_step=epoch)\n",
    "\n",
    "            ic(self.scheduler.get_last_lr())\n",
    "            last_lr = self.scheduler.get_last_lr()[0]\n",
    "            writer.add_scalar('learning rate', last_lr, global_step=epoch)\n",
    "            self.scheduler.step()\n",
    "            print(self.mse_avg)\n",
    "        writer.close()\n",
    "        # torch.optim.lr_scheduler.print_lr()\n",
    "\n",
    "    def predict(self, data: torch.Tensor):\n",
    "        with torch.no_grad():\n",
    "            points, freq = data\n",
    "            return print(f'predicted freq: {self.model(points)}, real freq: {freq}')\n",
    "\n",
    "\n",
    "dataset = SineDataset(64*2)\n",
    "train_data, test_data = random_split(dataset, [64, 64])\n",
    "\n",
    "neuro_net = NeuroNet()\n",
    "\n",
    "neuro_net.train_model(train_data, test_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0725f04f-c11e-425c-ab72-1eed416cb4d8",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "a = np.random.rand(3, 5)\n",
    "print(a)\n",
    "print(a[:, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "785c7aa2-59a3-4709-b517-bf64419028fc",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "rnn = nn.LSTM(10, 20, num_layers=2, batch_first = True)\n",
    "input = torch.randn(3, 240, 10)\n",
    "h0 = torch.randn(2, 3, 20)\n",
    "c0 = torch.randn(2, 3, 20)\n",
    "output1, (hn, cn) = rnn(input, (h0, c0))\n",
    "output1 = torch.permute(output1, (0, 2, 1))\n",
    "print(output1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9202eba-738f-449e-9c44-f91aa77be049",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "m = nn.Conv1d(20, 20, 20, stride=2)\n",
    "output2 = m(output1)\n",
    "print(output2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74ce3b90-e601-46db-951b-9747af7af7f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.rand(64,1,1)\n",
    "y = x.view(x.size(0), -1)\n",
    "z = torch.squeeze(x , 1)\n",
    "# print(y==z)\n",
    "w = z[::2]\n",
    "h = z[1::2]\n",
    "print(z.shape)\n",
    "print(w.shape)\n",
    "print[]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
